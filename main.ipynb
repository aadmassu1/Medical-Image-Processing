{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd0138da5f5cc65e9dd06ded25401927ebb39b29c8fb2c8c589b2f77fc6d1d5cc82",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Segment(img):\n",
    "    #using adaptiveThresholding technique\n",
    "    thresh = cv2.adaptiveThreshold(img,1,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,39, -27)\n",
    "    # Marker labelling\n",
    "    ret, markers = cv2.connectedComponents(thresh)\n",
    "    # First, find the contours:\n",
    "    thresh = np.uint8(markers>0)\n",
    "    contours,_ = cv2.findContours(thresh, 1, 2)\n",
    "    cnt = [cnt for cnt in contours if cv2.contourArea(cnt)>10]\n",
    "    return cnt, markers\n",
    "\n",
    "def MajorAxis(contour):\n",
    "    ellipse = cv2.fitEllipse(contour)\n",
    "    (xc,yc),(d1,d2),angle = ellipse\n",
    "    return max(d1,d2)/2\n",
    "#Now calculate perimeter(L), Area(S), circularity = 4*pi*S/L^2, majorAxis length, MinorAxis length from the mask\n",
    "def feature_extract(contours):\n",
    "    features = []\n",
    "    S_L = cv2.contourArea(contours[0])\n",
    "    features.append(S_L)\n",
    "    S_R = cv2.contourArea(contours[1])\n",
    "    features.append(S_R)\n",
    "    L_L = cv2.arcLength(contours[0],True)\n",
    "    features.append(L_L)\n",
    "    L_R = cv2.arcLength(contours[1],True)\n",
    "    features.append(L_R)\n",
    "    C_L = 4*np.pi*S_L/L_L**2\n",
    "    features.append(C_L)\n",
    "    C_R = 4*np.pi*S_R/L_R**2\n",
    "    features.append(C_R)\n",
    "    features.append(MajorAxis(contours[0]))\n",
    "    features.append(MajorAxis(contours[1]))\n",
    "    return features\n",
    "\n",
    "def unpack(path, Labels):\n",
    "    features =[]\n",
    "    labels = []\n",
    "    for label in Labels:\n",
    "        cur_path = path + '/' + label\n",
    "        cur_label = label\n",
    "        #unpacking\n",
    "        count=0\n",
    "        for image in os.listdir(cur_path):\n",
    "            if image.endswith(\".png\"):\n",
    "                count+=1\n",
    "                print(f\"Processing Image-{image} in {label}\")\n",
    "                #read and convert to gray scale\n",
    "                im = cv2.imread(cur_path+'/'+image)\n",
    "                im = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "                contours,markers = Segment(im)\n",
    "                features.append(feature_extract(contours))\n",
    "                labels.append(cur_label)\n",
    "    return features, labels\n",
    "\n",
    "def Accuracy(Prediction, labels):\n",
    "    count=0\n",
    "    for predicted, label in zip(Prediction, labels):\n",
    "        if predicted == label:\n",
    "            count+=1\n",
    "    return 100*count/len(testing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Processing Image-NC3008.png in NC\nProcessing Image-NC3011.png in NC\nProcessing Image-NC3013.png in NC\nProcessing Image-NC3016.png in NC\nProcessing Image-NC3053.png in NC\nProcessing Image-NC3055.png in NC\nProcessing Image-NC3071.png in NC\nProcessing Image-NC3074.png in NC\nProcessing Image-NC3075.png in NC\nProcessing Image-NC3085.png in NC\nProcessing Image-NC3087.png in NC\nProcessing Image-NC3100.png in NC\nProcessing Image-NC3103.png in NC\nProcessing Image-NC3104.png in NC\nProcessing Image-NC3109.png in NC\nProcessing Image-NC3114.png in NC\nProcessing Image-NC3151.png in NC\nProcessing Image-NC3156.png in NC\nProcessing Image-NC3157.png in NC\nProcessing Image-NC3160.png in NC\nProcessing Image-NC3161.png in NC\nProcessing Image-NC3171.png in NC\nProcessing Image-NC3172.png in NC\nProcessing Image-NC3188.png in NC\nProcessing Image-NC3191.png in NC\nProcessing Image-NC3201.png in NC\nProcessing Image-NC3202.png in NC\nProcessing Image-NC3204.png in NC\nProcessing Image-PD3012.png in PD\nProcessing Image-PD3014.png in PD\nProcessing Image-PD3023.png in PD\nProcessing Image-PD3025.png in PD\nProcessing Image-PD3027.png in PD\nProcessing Image-PD3028.png in PD\nProcessing Image-PD3051.png in PD\nProcessing Image-PD3052.png in PD\nProcessing Image-PD3054.png in PD\nProcessing Image-PD3056.png in PD\nProcessing Image-PD3058.png in PD\nProcessing Image-PD3060.png in PD\nProcessing Image-PD3061.png in PD\nProcessing Image-PD3067.png in PD\nProcessing Image-PD3068.png in PD\nProcessing Image-PD3077.png in PD\nProcessing Image-PD3081.png in PD\nProcessing Image-PD3083.png in PD\nProcessing Image-PD3088.png in PD\nProcessing Image-PD3102.png in PD\nProcessing Image-PD3113.png in PD\nProcessing Image-PD3119.png in PD\nProcessing Image-PD3122.png in PD\n"
     ]
    }
   ],
   "source": [
    "training_path = 'Training'\n",
    "training_labels = os.listdir(training_path)\n",
    "training_features, training_labels = unpack(training_path, training_labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Processing Image-NC3000.png in NC\nProcessing Image-NC3009.png in NC\nProcessing Image-NC3029.png in NC\nProcessing Image-NC3057.png in NC\nProcessing Image-NC3064.png in NC\nProcessing Image-NC3070.png in NC\nProcessing Image-NC3072.png in NC\nProcessing Image-NC3115.png in NC\nProcessing Image-NC3169.png in NC\nProcessing Image-NC3811.png in NC\nProcessing Image-NC3812.png in NC\nProcessing Image-NC3813.png in NC\nProcessing Image-NC3816.png in NC\nProcessing Image-PD3018.png in PD\nProcessing Image-PD3059.png in PD\nProcessing Image-PD3076.png in PD\nProcessing Image-PD3080.png in PD\nProcessing Image-PD3086.png in PD\nProcessing Image-PD3089.png in PD\nProcessing Image-PD3118.png in PD\nProcessing Image-PD3123.png in PD\nProcessing Image-PD3330.png in PD\nProcessing Image-PD3331.png in PD\nProcessing Image-PD3332.png in PD\nProcessing Image-PD3333.png in PD\nProcessing Image-PD3378.png in PD\nProcessing Image-PD3380.png in PD\nProcessing Image-PD3392.png in PD\nProcessing Image-PD3403.png in PD\n"
     ]
    }
   ],
   "source": [
    "testing_path = 'Testing'\n",
    "testing_labels = os.listdir(training_path)\n",
    "testing_features, testing_labels = unpack(testing_path, testing_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training features: (51, 8)\nTraining labels: (51,)\n"
     ]
    }
   ],
   "source": [
    "print (\"Training features: {}\".format(np.array(training_features).shape))\n",
    "print (\"Training labels: {}\".format(np.array(training_labels).shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing both data the data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(training_features)\n",
    "training_data = scaler.transform(training_features)\n",
    "testing_data = scaler.transform(testing_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[STATUS] Creating the classifier..\n[STATUS] Fitting data/label to model..\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LinearSVC(random_state=9)"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "# create the classifier\n",
    "print(\"[STATUS] Creating the classifier..\")\n",
    "clf_svm = LinearSVC(random_state=9, max_iter=1000)\n",
    "# fit the training data and labels\n",
    "print(\"[STATUS] Fitting data/label to model..\")\n",
    "clf_svm.fit(training_data, training_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "96.55172413793103\n"
     ]
    }
   ],
   "source": [
    "#prediction\n",
    "Prediction = [clf_svm.predict(feature.reshape(1, -1))[0] for feature in testing_data]\n",
    "model_accuracy = Accuracy(Prediction, testing_labels)\n",
    "print(model_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "label NC predicted as NC\nlabel NC predicted as PD\nlabel NC predicted as NC\nlabel NC predicted as NC\nlabel NC predicted as NC\nlabel NC predicted as NC\nlabel NC predicted as NC\nlabel NC predicted as NC\nlabel NC predicted as NC\nlabel NC predicted as NC\nlabel NC predicted as NC\nlabel NC predicted as NC\nlabel NC predicted as NC\nlabel PD predicted as PD\nlabel PD predicted as PD\nlabel PD predicted as PD\nlabel PD predicted as PD\nlabel PD predicted as NC\nlabel PD predicted as PD\nlabel PD predicted as PD\nlabel PD predicted as PD\nlabel PD predicted as PD\nlabel PD predicted as PD\nlabel PD predicted as PD\nlabel PD predicted as PD\nlabel PD predicted as PD\nlabel PD predicted as PD\nlabel PD predicted as PD\nlabel PD predicted as PD\n"
     ]
    }
   ],
   "source": [
    "for p,l in zip(Prediction, testing_labels):\n",
    "    print(f'label {l} predicted as {p}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}